{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "\n",
    "To find the most suitable locations for wind farms, we look to NOAA (National Oceanic and Atmospheric Administration) for data about wind speeds observed at their stations.\n",
    "\n",
    "The source data for this is a very large file (\"ghcnd-all.tar.gz\") which yields perhaps thousands of individual station \".dly\" files.\n",
    "\n",
    "Assisting us in distilling this massive amount of data are other files: inventory.txt and station.txt.  Inventory.txt tells us which stations monitor which elements of weather.  \n",
    "\n",
    "A few of the .dly files have been uploaded to rawdata in the Github repository; there are far too many and collectively far too large to retain all of them.  Also, weatherdata files and inventory.txt must be zipped up in order to meet Github's size limit.\n",
    "\n",
    "\n",
    "## inventory_select\n",
    "\n",
    "inventory_select was created to process the inventory file.\n",
    "\n",
    "-  reads \"inventory.txt\"\n",
    "-  breaks up into rows and fields\n",
    "-  select only US stations (which conveniently have IDs beginning with \"US\")\n",
    "-  select only stations which monitor desired data, as indicated by \"elements\"\n",
    "-  creates an \"inventory.csv\" file for possible future use\n",
    "-  also creates a list of unique stations within the scope of our attention\n",
    "\n",
    "## weatherdata_select\n",
    "\n",
    "weatherdata_select uses the list of unique stations to gather and parse the .dly files\n",
    "\n",
    "-  reads \"station_list.csv\".  Each row contains one station id.\n",
    "-  use the station id to read its corresponding \"dly\" file\n",
    "-  break it up into rows and fields\n",
    "-  save only the relevant \"element\" records\n",
    "-  write out weatherdata.csv\n",
    "\n",
    "##  find_weatherdata_values\n",
    "\n",
    "The weatherdata file produced above contains one row per station per monthy, but still needs more processing.  It has one large \"values\" field which needs to be broken up into its 31 daily values in order to be useful.\n",
    "\n",
    "-  take this big value field, and extract the values for each individual day\n",
    "-  find the mean of each month's worth of daily values, discarding any missing data\n",
    "-  write this back out as weatherdata_v2.csv\n",
    "\n",
    "##  parse_station_data\n",
    "\n",
    "It's useful to have a file containing a list of stations and their major attributes\n",
    "(e.g. latitudes, longitudes)\n",
    "\n",
    "-  read in stations.txt\n",
    "-  break up into rows and fields\n",
    "-  write back out as stations.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
